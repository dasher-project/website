HiddenPage 制作训练文本
<h2>制作训练文本</h2>
<p> 训练文本应该是包含和你想输入的内容类似内容的纯文本文件.
 越大越好.
 我们认为300K 是比较合适的.
</p><p>
 你可以使用的范例训练文件像是:
<ul>
  <li>把你输入过的所有的文本连接成一个大的文本文件. 
</li>
  <li>使用小说 - 像是我们采用了来自<a href=http://promo.net/pg/>Project Gutenberg</a>的 Jane Austen's <em>Emma</em>.
  但使用一两本小说的问题是某些特定单词(像是Emma , Alice)
  出现的次数很多;所以小说不是一个理想的一般用途的训练文本.
</li>
       <li>把你所有的电子邮件合成一个大的文本..
</li>
     </ul>

<h3>怎样创建一个一般用途的训练文本</h3>     
 这里是我创建英文Dasher训练文本的过程
<ol>
  <li>
       取得尽可能多的英文文件,
       以便能如下一样合理地选出一个<em>均衡的(well-balanced)</em>
       句子的集合.
       </li>
  <li>
       进行预处理使得每行只有一个句子.
<br>   我是用我写的一个perl程序来完成,
       <a href=/mackay/perl/processbook.p>processbook.p</a>
       里面的脚本程序像是这样
           <pre>foreach f ( alice emma )
  processbook.p  /books0/$f > /books/$f
end
</pre>       
       </li>
  <li><b>现在</b>, 得到这个语种里最常用的2000个单词的列表
       . 想法是既然这些单词是常见的，在最后的文集(corpus)里我们就要确保它们在各种上下文中都出现几次.
       我们将使用这些单词来选择总文集中的句子.
       <br>
       我从internet上得到这样的一个列表,然后将它放入一个叫 <tt>dict</tt>的文件里.
       我把一些荒谬的常见单词从dict里去掉确保下面的步骤能很好的进行.
       </li>
  <li>
       用另一个程序来从经过与处理的文件里选出包含2000个必需单词的句子.
       按顺序处理单词使得最后的文集也是有序的, 文集的最开始包括最常见单词的范例
       ; 这样, 即便文集去掉最后的部分,也是适当的.
       <br>
       将句子连接在一起合成长度合理的段落, 来仿效正常的写作.
       <br>
       我通过使用linux下的应用程序<b>glimpse</b> 和自己的perl
       程序<a href=/mackay/perl/corpus.p>corpus.p</a>
       <pre>rm  /data/coll/mackay/books/*~
glimpseindex -b  -B   -H ~/dasher/  /data/coll/mackay/books/
corpus.p k=1 f=4 o=corpus4.txt
       </pre>
       这就是我如何制作出在 Dasher 1.6.8中使用的<a href=/dasher/download/english/corpus4.txt1>这个文集</a> (316K),
      .
       </li>
</ol>

</p><p>
 如果有谁制作出了其他语言的好的文集并愿意共享,我可以将它们放在
  <a href=/dasher/download/>这个站点</a>.
</p>